{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e96dcf9-7bf4-4138-80f1-0f1506e2e586",
   "metadata": {},
   "source": [
    "# A quick tutorial to RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad02a31-352f-4641-865c-1c7f93e69b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from src.config import Configuration\n",
    "conf =  Configuration()\n",
    "HUGGING_FACE_KEY = conf.load_hg_token(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90fc81d1-faef-4749-84a3-d536ff39c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding model\n",
    "# MODEL = \"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\"\n",
    "MODEL = \"sentence-transformers/LaBSE\"\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=HUGGING_FACE_KEY,\n",
    "    model_name=MODEL)\n",
    "\n",
    "# insert data to vector store\n",
    "texts = [\"Huy là lập trình viên\", \"John là người Mỹ\", \"Kiệt là kĩ sư\",\n",
    "        \"Hiếu là họa sĩ\", \"Khoa là giám đốc\", \"Tài là người kinh doanh\",\n",
    "        \"Ngân là một tư vấn viên\", \"Quang Trung là một vị hoàng đế\",\n",
    "        \"Quang Lê là ca sĩ\", \"Kỳ Duyên là người dẫn chương trình\",\n",
    "        \"Vạn Thịnh Phát là đại gia\"]\n",
    "\n",
    "docs = [Document(page_content=t, metadata={\"id\": id}) for id, t in enumerate(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9375a67a-b4a7-41c8-a01c-d06809886056",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfdc88-99a5-4531-8644-7ba8ef21aa15",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863878f4-012b-44d9-9f61-792fd92053b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Quang Lê là ca sĩ', metadata={'id': 8}), 0.86171794),\n",
       " (Document(page_content='Quang Trung là một vị hoàng đế', metadata={'id': 7}),\n",
       "  1.0207201)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Những người có tên Quang\"\n",
    "res = faiss_db.similarity_search_with_score(query, k=2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5f6e2-0300-40d2-b33b-86ad17706f53",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da12e8a-fda1-4702-9007-b5d41292a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # the other func consumes the result of this func\n",
    "            return other(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "\n",
    "class MyRunnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # the other func consumes the result of this func\n",
    "            print(\"invoke\")\n",
    "            return other(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9b1b1f-ff95-402d-baa0-153064716232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-pro\", \n",
    "            temperature=0, \n",
    "            google_api_key=conf.load_gemini_token()\n",
    "        )\n",
    "\n",
    "template = \"\"\"\\\n",
    "    Answer the question based only on the following context:\\n \\\n",
    "        {context} \\\n",
    "    \\nQuestion: {question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "class MemoryLog:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "        self.state = {}\n",
    "    \n",
    "    def log(self, e):\n",
    "        self.memory.append(e)\n",
    "        return e\n",
    "\n",
    "    def store(self, e):\n",
    "        # self.state.append(e)\n",
    "        self.state[e['id']] = e\n",
    "        return e\n",
    "\n",
    "    def parse(self, e):\n",
    "        data = {**e}\n",
    "        data_str = \"\"\n",
    "        for c in e['context']:\n",
    "            data_str += (\"\\n- \" + c.page_content)\n",
    "        data['context'] = data_str\n",
    "        return data\n",
    "    \n",
    "mem = MemoryLog()\n",
    "\n",
    "retriever = faiss_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "rag = (\n",
    "    {\"context\": itemgetter(\"question\") | faiss_db.as_retriever(), \"question\": itemgetter(\"question\"), \"id\": itemgetter(\"id\")}\n",
    "    | RunnableLambda(lambda e: mem.log(e))\n",
    "    | RunnableLambda(lambda e: mem.parse(e))\n",
    "    | RunnableLambda(lambda e: mem.store(e))\n",
    "    | prompt\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b512994-21f2-4ea6-8934-54d8f309e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "conf.enable_tracing(project=\"LEARN\")\n",
    "\n",
    "@traceable(tags=[\"rag_lcel_multi_input\"])\n",
    "def ask_rag(question):\n",
    "    a = rag.invoke({\"question\": question, \"id\": \"hieu-ai\"})\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9694d76-6948-4a9d-8e15-81e0b9123962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Họa sĩ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ask_rag(\"Hiếu là ai?\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a58b13e-febd-43b6-afef-13aee25f0613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Hiếu là họa sĩ', metadata={'id': 3}),\n",
       "  Document(page_content='Huy là lập trình viên', metadata={'id': 0}),\n",
       "  Document(page_content='John là người Mỹ', metadata={'id': 1}),\n",
       "  Document(page_content='Quang Lê là ca sĩ', metadata={'id': 8})],\n",
       " 'question': 'Hiếu là ai?',\n",
       " 'id': 'hieu-ai'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = mem.memory[0]\n",
    "{**b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9658c454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hieu-ai': {'context': '\\n- Hiếu là họa sĩ\\n- Huy là lập trình viên\\n- John là người Mỹ\\n- Quang Lê là ca sĩ',\n",
       "  'question': 'Hiếu là ai?',\n",
       "  'id': 'hieu-ai'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b131442d-2fb1-45d3-8422-ae4c50e844b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"topic\": RunnablePassthrough()}\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fdc842-6b16-451b-ae93-6f58cf3679ac",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/chroma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
