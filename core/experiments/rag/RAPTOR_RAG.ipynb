{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAPTOR RAG\n",
    "\n",
    "*_Algorithm_*\n",
    "- Input: array of strings\n",
    "- Step 1: split each string into contiguous chunks with len <= 100\n",
    "- Step 2: group chunks into clusters\n",
    "- step 3: summarize the clusters\n",
    "\n",
    "Ref: https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons\n",
    "- split the orginal text into chunks\n",
    "- embed question into document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from src.utils.text_utils import create_splitter\n",
    "\n",
    "splitter = create_splitter(chunk_size=400, overlap=50, separators=[\".\", \"\\n\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'content', 'doc_id', 'metadata', 'split', 'shards', 'propositions', 'proposition_list'],\n",
       "    num_rows: 257\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# REPO = 'BroDeadlines/TEST.edu_tdt_proposition_data'\n",
    "# SPLIT = 'TEST.basic_index_TDT_clean'\n",
    "REPO = \"BroDeadlines/TEST.UEH.ueh_copora_data\"\n",
    "SPLIT = 'train'\n",
    "repo_data = load_dataset(REPO, split=SPLIT)\n",
    "repo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.type_utils import create_langchain_doc\n",
    "\n",
    "docs_texts = []\n",
    "\n",
    "def make_langchain_documents2(row):\n",
    "    docs = splitter.create_documents([row['content']], [{\"doc_id\": row['doc_id']}])\n",
    "    docs_texts.extend(docs)\n",
    "    return row\n",
    "    \n",
    "d = repo_data.map(make_langchain_documents2)\n",
    "len(docs_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_texts[0].metadata['doc_id'] == docs_texts[1].metadata['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAPTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag.raptor import RAPTOR\n",
    "from src.service.provider import ProviderService\n",
    "provider = ProviderService()\n",
    "raptor = RAPTOR(provider)\n",
    "\n",
    "vec_idx = \"vec-raptor-ueh-tree\"\n",
    "text_idx = \"text-raptor-ueh-tree\"\n",
    "\n",
    "es = provider.get_elasticsearch_store(vec_idx)\n",
    "bm = provider.get_elasticsearch_bm25(text_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "raptor.log - ERROR - [ERROR] .\n",
      "Phấn đấu học tập thật tốt từ khi mới vào trường để đạt được mục tiêu.\n",
      "Quản lý giữa công việc và việc học tập một cách hợp lý\n",
      "1. ĐIỀU KIỆN XÉT VÀ CÔNG NHẬN TỐT NGHIỆP\n",
      "\n",
      "ĐẠI HỌC\n",
      "\n",
      "Điều kiện xét và công nhận tốt nghiệp\n",
      "1. Sinh viên được công nhận và cấp bằng tốt nghiệp bậc đại học, loại hình đào tạo chính quy nếu hội đủ các điều kiện sau đây:\n",
      "a) Tích lũy đủ học phần, số tín chỉ và hoàn thành các nội dung bắt buộc khác theo yêu cầu của CTĐT, đạt chuẩn đầu ra của CTĐT;\n",
      "b) Điểm trung bình tích lũy của toàn khóa học đạt từ trung bình trở lên;\n",
      "c) Tại thời điểm xét tốt nghiệp không bị truy cứu trách nhiệm hình sự hoặc không đang trong thời gian bị kỷ luật ở mức đình chỉ học tập.\n",
      "2. Mỗi học kỳ chính, Hội đồng xét tốt nghiệp bậc đại học, loại hình đào tạo chính quy tiến hành xem xét và thông qua danh sách những sinh viên đủ điều kiện tốt nghiệp. Dựa trên đề nghị của Hội đồng xét tốt nghiệp, Hiệu trưởng ban hành quyết định công nhận tốt nghiệp.\n",
      "3. Sinh viên tốt nghiệp được nhận Bằng cử nhân và Phụ lục văn bằng trong thời hạn 03 tháng tính từ thời điểm Hiệu trưởng ban hành quyết định công nhận tốt nghiệp. Trên Phụ lục văn bằng ghi thông tin sinh viên, thông tin về văn bằng, hình thức đào tạo chính quy, các thông tin về ngành đào tạo, chi tiết tất cả kết quả học tập của sinh viên theo từng học phần.\n",
      "4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\", line 79, in error_remapped_callable\n",
      "    return callable_(*args, **kwargs)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/grpc/_channel.py\", line 1160, in __call__\n",
      "    return _end_unary_response_blocking(state, call, False, None)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/grpc/_channel.py\", line 1003, in _end_unary_response_blocking\n",
      "    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n",
      "grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.RESOURCE_EXHAUSTED\n",
      "\tdetails = \"Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:817684272890'.\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.175.95:443 {created_time:\"2024-08-12T23:06:16.071876622+07:00\", grpc_status:8, grpc_message:\"Quota exceeded for quota metric \\'Batch Embed Content API requests\\' and limit \\'Batch embed contents request limit per minute for a region\\' of service \\'generativelanguage.googleapis.com\\' for consumer \\'project_number:817684272890\\'.\"}\"\n",
      ">\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/langchain_google_genai/embeddings.py\", line 63, in _embed\n",
      "    result = genai.embed_content(\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/generativeai/embedding.py\", line 156, in embed_content\n",
      "    embedding_response = client.batch_embed_contents(embedding_request)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 1093, in batch_embed_contents\n",
      "    response = rpc(\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/retry.py\", line 372, in retry_wrapped_func\n",
      "    return retry_target(\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/retry.py\", line 207, in retry_target\n",
      "    result = target()\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\", line 81, in error_remapped_callable\n",
      "    raise exceptions.from_grpc_error(exc) from exc\n",
      "google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:817684272890'. [reason: \"RATE_LIMIT_EXCEEDED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_metric\"\n",
      "  value: \"generativelanguage.googleapis.com/batch_embed_contents_requests\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_location\"\n",
      "  value: \"us-west4\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit\"\n",
      "  value: \"BatchEmbedContentsRequestsPerMinutePerProjectPerRegion\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit_value\"\n",
      "  value: \"150\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/817684272890\"\n",
      "}\n",
      ", links {\n",
      "  description: \"Request a higher quota limit.\"\n",
      "  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n",
      "}\n",
      "]\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/h4438/Desktop/graduate/WebQA/core/experiments/rag/../../src/rag/raptor.py\", line 228, in embed\n",
      "    embeddings = self.embd.embed_query(text=text)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/langchain_google_genai/embeddings.py\", line 99, in embed_query\n",
      "    return self._embed([text], task_type=task_type)[0]\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/langchain_google_genai/embeddings.py\", line 70, in _embed\n",
      "    raise GoogleGenerativeAIError(f\"Error embedding content: {e}\") from e\n",
      "langchain_google_genai._common.GoogleGenerativeAIError: Error embedding content: 429 Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:817684272890'. [reason: \"RATE_LIMIT_EXCEEDED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_metric\"\n",
      "  value: \"generativelanguage.googleapis.com/batch_embed_contents_requests\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_location\"\n",
      "  value: \"us-west4\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit\"\n",
      "  value: \"BatchEmbedContentsRequestsPerMinutePerProjectPerRegion\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit_value\"\n",
      "  value: \"150\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/817684272890\"\n",
      "}\n",
      ", links {\n",
      "  description: \"Request a higher quota limit.\"\n",
      "  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n",
      "}\n",
      "]\n",
      "raptor.log - ERROR - [ERROR] .\n",
      "Phấn đấu học tập thật tốt từ khi mới vào trường để đạt được mục tiêu.\n",
      "Quản lý giữa công việc và việc học tập một cách hợp lý\n",
      "1. ĐIỀU KIỆN XÉT VÀ CÔNG NHẬN TỐT NGHIỆP\n",
      "\n",
      "ĐẠI HỌC\n",
      "\n",
      "Điều kiện xét và công nhận tốt nghiệp\n",
      "1. Sinh viên được công nhận và cấp bằng tốt nghiệp bậc đại học, loại hình đào tạo chính quy nếu hội đủ các điều kiện sau đây:\n",
      "a) Tích lũy đủ học phần, số tín chỉ và hoàn thành các nội dung bắt buộc khác theo yêu cầu của CTĐT, đạt chuẩn đầu ra của CTĐT;\n",
      "b) Điểm trung bình tích lũy của toàn khóa học đạt từ trung bình trở lên;\n",
      "c) Tại thời điểm xét tốt nghiệp không bị truy cứu trách nhiệm hình sự hoặc không đang trong thời gian bị kỷ luật ở mức đình chỉ học tập.\n",
      "2. Mỗi học kỳ chính, Hội đồng xét tốt nghiệp bậc đại học, loại hình đào tạo chính quy tiến hành xem xét và thông qua danh sách những sinh viên đủ điều kiện tốt nghiệp. Dựa trên đề nghị của Hội đồng xét tốt nghiệp, Hiệu trưởng ban hành quyết định công nhận tốt nghiệp.\n",
      "3. Sinh viên tốt nghiệp được nhận Bằng cử nhân và Phụ lục văn bằng trong thời hạn 03 tháng tính từ thời điểm Hiệu trưởng ban hành quyết định công nhận tốt nghiệp. Trên Phụ lục văn bằng ghi thông tin sinh viên, thông tin về văn bằng, hình thức đào tạo chính quy, các thông tin về ngành đào tạo, chi tiết tất cả kết quả học tập của sinh viên theo từng học phần.\n",
      "4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\", line 79, in error_remapped_callable\n",
      "    return callable_(*args, **kwargs)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/grpc/_channel.py\", line 1160, in __call__\n",
      "    return _end_unary_response_blocking(state, call, False, None)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/grpc/_channel.py\", line 1003, in _end_unary_response_blocking\n",
      "    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n",
      "grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.RESOURCE_EXHAUSTED\n",
      "\tdetails = \"Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:817684272890'.\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.175.95:443 {created_time:\"2024-08-12T23:06:16.071876622+07:00\", grpc_status:8, grpc_message:\"Quota exceeded for quota metric \\'Batch Embed Content API requests\\' and limit \\'Batch embed contents request limit per minute for a region\\' of service \\'generativelanguage.googleapis.com\\' for consumer \\'project_number:817684272890\\'.\"}\"\n",
      ">\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/langchain_google_genai/embeddings.py\", line 63, in _embed\n",
      "    result = genai.embed_content(\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/generativeai/embedding.py\", line 156, in embed_content\n",
      "    embedding_response = client.batch_embed_contents(embedding_request)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 1093, in batch_embed_contents\n",
      "    response = rpc(\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/retry.py\", line 372, in retry_wrapped_func\n",
      "    return retry_target(\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/retry.py\", line 207, in retry_target\n",
      "    result = target()\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\", line 81, in error_remapped_callable\n",
      "    raise exceptions.from_grpc_error(exc) from exc\n",
      "google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:817684272890'. [reason: \"RATE_LIMIT_EXCEEDED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_metric\"\n",
      "  value: \"generativelanguage.googleapis.com/batch_embed_contents_requests\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_location\"\n",
      "  value: \"us-west4\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit\"\n",
      "  value: \"BatchEmbedContentsRequestsPerMinutePerProjectPerRegion\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit_value\"\n",
      "  value: \"150\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/817684272890\"\n",
      "}\n",
      ", links {\n",
      "  description: \"Request a higher quota limit.\"\n",
      "  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n",
      "}\n",
      "]\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/h4438/Desktop/graduate/WebQA/core/experiments/rag/../../src/rag/raptor.py\", line 228, in embed\n",
      "    embeddings = self.embd.embed_query(text=text)\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/langchain_google_genai/embeddings.py\", line 99, in embed_query\n",
      "    return self._embed([text], task_type=task_type)[0]\n",
      "  File \"/home/h4438/miniconda3/envs/uni/lib/python3.9/site-packages/langchain_google_genai/embeddings.py\", line 70, in _embed\n",
      "    raise GoogleGenerativeAIError(f\"Error embedding content: {e}\") from e\n",
      "langchain_google_genai._common.GoogleGenerativeAIError: Error embedding content: 429 Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:817684272890'. [reason: \"RATE_LIMIT_EXCEEDED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_metric\"\n",
      "  value: \"generativelanguage.googleapis.com/batch_embed_contents_requests\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_location\"\n",
      "  value: \"us-west4\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit\"\n",
      "  value: \"BatchEmbedContentsRequestsPerMinutePerProjectPerRegion\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"quota_limit_value\"\n",
      "  value: \"150\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/817684272890\"\n",
      "}\n",
      ", links {\n",
      "  description: \"Request a higher quota limit.\"\n",
      "  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at generate embeddings\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (769) does not match length of index (770)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m leaf_ids \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs_texts]\n\u001b[1;32m      2\u001b[0m leaf_texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs_texts]\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mraptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive_embed_cluster_summarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleaf_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/graduate/WebQA/core/experiments/rag/../../src/rag/raptor.py:367\u001b[0m, in \u001b[0;36mRAPTOR.recursive_embed_cluster_summarize\u001b[0;34m(self, texts, list_ids, level, n_levels)\u001b[0m\n\u001b[1;32m    364\u001b[0m results \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Dictionary to store results at each level\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Perform embedding, clustering, and summarization for the current level\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m df_clusters, df_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_cluster_summarize_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Store the results of the current level\u001b[39;00m\n\u001b[1;32m    370\u001b[0m results[level] \u001b[38;5;241m=\u001b[39m (df_clusters, df_summary)\n",
      "File \u001b[0;32m~/Desktop/graduate/WebQA/core/experiments/rag/../../src/rag/raptor.py:305\u001b[0m, in \u001b[0;36mRAPTOR.embed_cluster_summarize_texts\u001b[0;34m(self, texts, list_ids, level)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03mEmbeds, clusters, and summarizes a list of texts. This function first generates embeddings for the texts,\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03mclusters them based on similarity, expands the cluster assignments for easier processing, and then summarizes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m    and the cluster identifiers.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Embed and cluster the texts, resulting in a DataFrame with 'text', 'embd', 'cluster', 'doc_ids' columns\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m df_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_cluster_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Prepare to expand the DataFrame for easier manipulation of clusters\u001b[39;00m\n\u001b[1;32m    308\u001b[0m expanded_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/graduate/WebQA/core/experiments/rag/../../src/rag/raptor.py:264\u001b[0m, in \u001b[0;36mRAPTOR.embed_cluster_texts\u001b[0;34m(self, texts, list_ids)\u001b[0m\n\u001b[1;32m    262\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()  \u001b[38;5;66;03m# Initialize a DataFrame to store the results\u001b[39;00m\n\u001b[1;32m    263\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m texts  \u001b[38;5;66;03m# Store original texts\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(text_embeddings_np)  \u001b[38;5;66;03m# Store embeddings as a list in the DataFrame\u001b[39;00m\n\u001b[1;32m    265\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cluster_labels  \u001b[38;5;66;03m# Store cluster labels\u001b[39;00m\n\u001b[1;32m    266\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m list_ids\n",
      "File \u001b[0;32m~/miniconda3/envs/uni/lib/python3.9/site-packages/pandas/core/frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/uni/lib/python3.9/site-packages/pandas/core/frame.py:4300\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4292\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4293\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4298\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4300\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4303\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4305\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4306\u001b[0m     ):\n\u001b[1;32m   4307\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/uni/lib/python3.9/site-packages/pandas/core/frame.py:5039\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5039\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/uni/lib/python3.9/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (769) does not match length of index (770)"
     ]
    }
   ],
   "source": [
    "leaf_ids = [d.metadata['doc_id'] for d in docs_texts]\n",
    "leaf_texts = [d.page_content for d in docs_texts]\n",
    "results = raptor.recursive_embed_cluster_summarize(leaf_texts, leaf_ids, level=1, n_levels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaf_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                 text  \\\n",
       " 0   THÔNG TIN VỀ HỌC PHÍ, HỌC BỔNG DÀNH CHO SINH V...   \n",
       " 1   HỆ THỐNG CHỈ DẪN\\nUEH Wayfinding\\nXEM NGAY\\nKH...   \n",
       " 2   .\\n\\nĐiều khiển thông minh và tự động hóa (thu...   \n",
       " 3   .ueh.edu.vn/.\\n\\nTài khoản này sinh viên cũng ...   \n",
       " 4   UEH SHUTTLE BUS\\nTHUẬN TIỆN, AN TOÀN VÀ NHANH ...   \n",
       " 5   .edu.vn\\n\\nPhòng A0.04, cơ sở A\\n\\n(028) 7306 ...   \n",
       " 6   HỖ TRỢ THÔNG TIN – TƯ VẤN NGƯỜI HỌC\\n\\nPhòng C...   \n",
       " 7   .ueh.edu.vn”, trong đó: http (Hyper Text Trans...   \n",
       " 8   KHẢO SÁT CHẤT LƯỢNG HỌC PHẦN\\n\\nTrên tinh thần...   \n",
       " 9   .\\n\\nNgoài ra, còn có những quy định riêng khá...   \n",
       " 10  .\\n\\nThe opening of UEH English Zone is an exc...   \n",
       " 11  .\\n\\nChương trình đào tạo song ngành bao gồm: ...   \n",
       " 12  .\\n7\\tHoàn tất nghĩa vụ học phí.\\tTừ lúc đăng ...   \n",
       " 13  Trang chủ\\nTư vấn trước nhập học\\nĐại học chín...   \n",
       " 14  .\\n\\nNgoài ra, còn có những quy định riêng khá...   \n",
       " 15  . Sinh viên đăng ký học lại, học cải thiện điể...   \n",
       " 16  CHƯƠNG TRÌNH ĐÀO TẠO TRÌNH ĐỘ THẠC SĨ\\nĐẠI HỌC...   \n",
       " 17  .\\n\\nĐặc biệt Viện ILACS có các đối tác quốc t...   \n",
       " 18  . Hồ Chí Minh và Khoa Kinh tế của trường Đại h...   \n",
       " 19  ĐHCQ K49\\n\\nNgày 22/08/2023\\n\\nThông báo kết q...   \n",
       " \n",
       "                                                  embd     cluster  \\\n",
       " 0   [0.043042038, -0.015702775, -0.04887081, -0.01...       [1.0]   \n",
       " 1   [0.026773201, 0.010522383, -0.04385725, -0.044...       [3.0]   \n",
       " 2   [0.011247156, 0.0036593105, -0.04386811, -0.01...       [2.0]   \n",
       " 3   [0.017778916, -0.012684805, -0.03219656, -0.03...       [1.0]   \n",
       " 4   [0.012487903, -0.010146565, -0.058735665, -0.0...       [0.0]   \n",
       " 5   [0.022318687, 0.0067212624, -0.04468038, -0.03...       [4.0]   \n",
       " 6   [0.03155073, 0.019556511, -0.022321545, -0.035...       [0.0]   \n",
       " 7   [0.015652651, -0.014095937, -0.020236384, -0.0...       [1.0]   \n",
       " 8   [0.014524044, 0.012878216, -0.047118504, -0.02...       [1.0]   \n",
       " 9   [0.025102962, -0.008167905, -0.05110296, -0.02...  [0.0, 0.0]   \n",
       " 10  [0.020255635, -0.005935493, -0.04299145, -0.03...       [3.0]   \n",
       " 11  [0.03603926, -0.012416649, -0.03151774, -0.017...       [2.0]   \n",
       " 12  [0.020372912, 0.0021988791, -0.05896629, -0.02...       [2.0]   \n",
       " 13  [0.0027169518, 0.0044505545, -0.04459068, -0.0...       [3.0]   \n",
       " 14  [0.025102962, -0.008167905, -0.05110296, -0.02...  [0.0, 0.0]   \n",
       " 15  [0.031718142, -0.0018510345, -0.035929292, -0....       [2.0]   \n",
       " 16  [0.0031931517, 0.0025982822, -0.0520418, -0.01...       [2.0]   \n",
       " 17  [0.024382897, 0.0074588195, -0.029320724, -0.0...       [4.0]   \n",
       " 18  [0.002308648, 0.0051756874, -0.05403924, -0.01...       [1.0]   \n",
       " 19  [0.006702032, 0.015562974, -0.04718003, -0.024...       [3.0]   \n",
       " \n",
       "                                  doc_ids  \n",
       " 0   e53667f0-d952-4396-a0c3-745c8462d6fe  \n",
       " 1   da04b1b6-0e7a-4b49-b10b-62e35df1d71f  \n",
       " 2   4b64e4d0-f573-4b62-b581-1a71d21c2ae7  \n",
       " 3   63e18ee5-cf5c-49e1-9969-333b742cea09  \n",
       " 4   b8424155-e924-47d3-a0af-ed8f46d26274  \n",
       " 5   61ed537d-44d4-409f-9bdb-19a1d6d19a58  \n",
       " 6   e9ab4feb-0626-4a12-a930-655ba2b7d684  \n",
       " 7   63e18ee5-cf5c-49e1-9969-333b742cea09  \n",
       " 8   8d02768d-a55d-4bd3-a39e-e9b30e23a2ae  \n",
       " 9   c9c1052e-a06f-4cc0-a723-71b0f023ba50  \n",
       " 10  758e3696-a320-455a-bd68-ab52ac8bffa5  \n",
       " 11  0f59092d-c416-48ab-bc8c-fab42806378e  \n",
       " 12  cf2d8734-1888-4654-9515-9f283ace9edc  \n",
       " 13  969e80f4-33d1-411d-afec-a392df9d44c0  \n",
       " 14  028f2b03-fbac-43b5-b83f-97eb83d88942  \n",
       " 15  028f2b03-fbac-43b5-b83f-97eb83d88942  \n",
       " 16  d4572bff-55e0-4b59-ae34-0b8fad910ee4  \n",
       " 17  705c6452-ee40-457a-982f-784f78eeee89  \n",
       " 18  8ac8e469-1bd0-405a-94eb-558fed7e6d70  \n",
       " 19  666f34ba-ace9-4684-b335-5f2cad4a99e2  ,\n",
       "                                            summaries  level  cluster  \\\n",
       " 0  **Học phí:**\\n\\n* Đào tạo tại TP.HCM: Tăng học...      1      1.0   \n",
       " 1  Trang web của Đại học Kinh tế TP. Hồ Chí Minh ...      1      3.0   \n",
       " 2  **Điều khiển thông minh và tự động hóa**\\n\\n* ...      1      2.0   \n",
       " 3  UEH Shuttle Bus cung cấp dịch vụ xe buýt nhanh...      1      0.0   \n",
       " 4  Đại học Kinh tế TP. Hồ Chí Minh cung cấp các d...      1      4.0   \n",
       " \n",
       "                                              doc_ids  \n",
       " 0  e53667f0-d952-4396-a0c3-745c8462d6fe;63e18ee5-...  \n",
       " 1  da04b1b6-0e7a-4b49-b10b-62e35df1d71f;758e3696-...  \n",
       " 2  4b64e4d0-f573-4b62-b581-1a71d21c2ae7;0f59092d-...  \n",
       " 3  b8424155-e924-47d3-a0af-ed8f46d26274;e9ab4feb-...  \n",
       " 4  61ed537d-44d4-409f-9bdb-19a1d6d19a58;705c6452-...  )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all_texts with leaf_texts\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# Iterate through the results to extract summaries from each level and add them to all_texts\n",
    "for level in sorted(results.keys()):\n",
    "    # Extract summaries from the current level's DataFrame\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # Extend all_texts with the summaries from the current level\n",
    "    all_texts.extend(summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['47f38849-1954-48be-b704-da43d2597572',\n",
       " 'c92bddf0-e0fa-4084-9e1e-b3c81ea886be',\n",
       " '0a7d6320-b765-477f-8292-fbc7d41c218c',\n",
       " '3d144d23-49aa-4626-b020-2aa3b4551823',\n",
       " 'c204ed90-856b-4211-8dd7-08d87e92df1c',\n",
       " 'b85102cc-02be-445e-a8ee-d2264d9e0f05',\n",
       " 'f1217387-375b-46b9-9ccb-65742b57fc65',\n",
       " '8abd27c4-5109-4d33-bf6e-6644bcf961f9',\n",
       " '7b4ddbf4-3776-4bea-8d36-bdf1ca721efd',\n",
       " '3247568c-fdc3-47ac-8d22-83071f9adc97',\n",
       " '3be1129d-ed18-4be3-bd3a-258bd06affff',\n",
       " '51583add-e783-4a00-8de7-98f21286861a',\n",
       " 'f936ff60-db0c-4f04-8949-81213ec52e98',\n",
       " '68c1a8b7-eb4d-4ad1-ad25-e319b444cfd5',\n",
       " '8f790270-b72b-4b35-88ce-7975120382bf',\n",
       " 'bec563ca-1380-429d-9020-66f6240ca7a5',\n",
       " 'c3742ed2-8d00-47cf-82df-2e84213a52f7',\n",
       " 'ce8f4ef9-cb35-4e3c-a473-aba7f7930338',\n",
       " '843ecbca-61ba-4f4d-acde-aac07d76f263',\n",
       " 'e925776e-4b38-4a89-b45c-b8b45f00d58b',\n",
       " '85711b1e-50a4-4a8d-9962-f5647de64c13',\n",
       " '6d67353c-6317-4bfd-b933-55913d440770',\n",
       " 'b27f67c6-88bf-4818-8b5d-080b15744465',\n",
       " '7569b12b-7f1d-4b9d-90e5-4c459a91cc92',\n",
       " '2988d5dc-3503-4610-81e5-605813f08779',\n",
       " 'e4186189-a743-471c-aa7f-4a455354b405']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.add_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21122dff-1f46-4787-bd63-713df8098a0e',\n",
       " 'babbc467-c0ee-4375-b335-66c814e47e3d',\n",
       " '8aa1d03b-9bcd-4565-8345-f3a0c4a7a59c',\n",
       " '56b72a66-ae1a-40d6-8d70-54632a3e74ff',\n",
       " '8d9fc87c-eda0-4874-9c65-4449101b5ec3',\n",
       " 'eb1499b6-5a27-4928-911f-c632276e233a',\n",
       " '3a75ef5a-8edd-48e1-890a-ae20db7e1b0d',\n",
       " 'ae5df7e9-ced7-4b28-803e-00d143007198',\n",
       " 'a3f683c5-bffa-4983-aa37-a5e8eb6bd54f',\n",
       " 'c249eb1c-d550-443c-adf3-f6aee6506eb9',\n",
       " 'a83d023a-6c7e-4862-8927-dd5cb07b98af',\n",
       " 'a6d13540-d452-4887-b1e1-f5e2784e6596',\n",
       " '3ca9b98c-9967-4f95-a8d9-c5b4e7199613',\n",
       " '18850611-9bd9-4284-b6f6-c3aac3ff101e',\n",
       " '1c986f23-72e9-4334-bd40-a87e0b8e838e',\n",
       " '6400486c-4234-4bfb-914d-c9d7c2d66ff8',\n",
       " '877bb1c2-9c9f-404e-87d9-5fa4a13a1904',\n",
       " '59989e58-62ba-4e2e-a497-92cac7cd10de',\n",
       " 'de8e116c-47de-4763-854e-c5e0df08997f',\n",
       " '0e3fd5d3-39ea-4aae-aa1d-bd7c584b400d',\n",
       " '5ac1fe16-8858-4d61-b578-fc6407b39d46',\n",
       " 'deeba63c-c079-4bd5-af8b-84fd2b02926d',\n",
       " 'f22724a4-5f00-46a5-b452-38c3ffe19810',\n",
       " 'ecb5a0a7-a79f-4c30-bebb-4509c583dc0e',\n",
       " '0ad40243-1033-401c-b43f-8399246ac439',\n",
       " 'e6d97d08-080c-4e41-9826-819ac079578f']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.add_texts(all_texts, metadatas={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag.hyde_rag import HydeRAG, HydeHybridSearchRAG\n",
    "from src.utils.config_utils import get_gemini_hyde_config\n",
    "\n",
    "# rag = HydeRAG(provider=provider, index=\"test-basic_test_tdt_dataset\")\n",
    "config = get_gemini_hyde_config()\n",
    "config.vector_index = vec_idx\n",
    "config.text_index = text_idx\n",
    "\n",
    "# config.vector_index = \"vec-sentence-propositon_medium_edu_tdt\"\n",
    "# config.text_index = 'text-sentence-propositon_medium_edu_tdt'\n",
    "\n",
    "# rag = HydeRAG(provider=provider, index=config.vector_index)\n",
    "rag = HydeHybridSearchRAG(provider=provider,config=config, k=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "retriever = rag.ensemble_retriever\n",
    "model = provider.get_simple_gemini_pro()\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "# rag_chain.invoke(\"How to define a RAG chain? Give me a specific code example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.config.enable_tracing(\"CODEBOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tôi không tìm thấy thông tin về mối liên hệ giữa các lỗi vi phạm của sinh viên ở ký túc xá với kết quả học tập rèn luyện của họ trong tài liệu được cung cấp.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "\n",
    "# ques = \"Lệ phí tập sự nghề nghiệp,ôn và thi tốt nghiệp,khóa luận tính như thế nào\"\n",
    "ques = \"Sinh viên muốn làm giấy xác nhận để đi xe buýt thì phải làm sao\"\n",
    "ques = \"Sinh viên thi TOEIC/MOS do IIG tổ chức tại trường Đại học Tôn Đức Thắng nhưng CMND bị mờ, ép dẻo, ép lụa, ép lại, bong tróc mép để hở phần giấy bên trong thì làm thế nào\"\n",
    "ques = \"Các lỗi vi phạm khi Sinh viên ở ký túc xá có liên quan hay ảnh hưởng gì với kết quả học tập rèn luyện gì trường học hay không\"\n",
    "answ = rag_chain.invoke(ques)\n",
    "\n",
    "answ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
